- сделать альтернативную батчевую обработку курсов в транзакции
- проверить эвикшн полиси, memory pressure
- подумать о деплойменте редиса: какие гарантии он дает и как часто реализован бэкап. Нужно ли дополнительно обрабатывать кейс восстановления с бэкапа и как?
- добавить крон обработчик, который обновляет все котировки
- отрисовать схему в красивом виде
- CORS?
- какие индексы стоит добавить в БД?
- проверить, что ошибка unique constr обрабатывается корректно

Testing:
-  Протестировать Postgres-репозиторий
Прямая работа с БД — самый большой риск. Ошибка в SQL приведет к падению сервиса.
Синтаксис SQL, маппинг данных в Quote, обработка уникальных нарушений (isUniqueViolation).
Интеграционный тест с тестовой БД (Docker, testcontainers-go или sqlmock)

- Протестировать логику кэширования в GetLatestQuote
Некорректный кэш приведет к устаревшим данным или лишним запросам.
3 сценария: попадание в кэш, промах -> загрузка из БД, промах -> БД пуста.
Модульный тест с моком Redis. Проверить цепочку вызовов и обновление кэша.

- Протестировать внешний провайдер (ExchangeRateHostProvider)
Зависимость от чужого API. Нужно убедиться, что парсинг ответов и обработка ошибок работают.
Успешный ответ, ошибки сети/таймаута, некорректный JSON, неожиданная структура ответа.
Модульный тест с httptest.Server, эмулирующим разные ответы API.

Реализация:
- Внедрить сквозную трассировку (request_id)	ID запроса из API не передается в фоновые задачи, что делает логи несвязными.	Высокий	Низкая	Без этого невозможно отследить полный жизненный цикл запроса через API, сервис, воркер и БД. Это основа мониторинга.
- Атомизировать логику дедупликации в БД	Текущая логика SELECT -> INSERT подвержена состоянию гонки.	Высокий	Средняя	Может приводить к некорректному поведению (дублированию задач или возврату неверного ID) под нагрузкой, хотя целостность данных не нарушается.
-  Внедрить механизм отказоустойчивости для внешнего провайдера	Сервис полностью зависит от одного внешнего API (Single Point of Failure).	Критический	Высокая	Выход из строя провайдера остановит весь сервис. Это главная архитектурная уязвимость, но её исправление требует времени.
- Детализировать health-чек	Текущий /readyz не указывает, какая именно зависимость (Postgres/Redis) недоступна.	Средний	Низкая	Ускоряет диагностику при инцидентах. Позволяет быстро понять, в чем корень проблемы.
- Внедрить метрики (Prometheus)	Отсутствует мониторинг ключевых показателей: глубина очереди, время обработки, успешность запросов к провайдеру.	Средний	Средняя	Метрики — это "зрение" в production. Без них вы не увидите деградацию производительности до того, как она станет критической.
- Реализовать политику очистки старых данных	Таблица с результатами обновлений будет бесконечно расти.	Низкий	Средняя	Предотвратит неконтролируемый рост БД и постепенное замедление запросов.
- Написать в readme, что нужен transactional outbox




 Already done / not needed

──"Какие индексы стоит добавить в БД?" — Already handled. Your migration has idx_quotes_pair_time─for─latest-quote─lookups─and─uniq_quotes_pair_pending─for─dedup.
   These cover your two main query patterns. No additional indexes needed unless you add new query paths.

  "Проверить, что ошибка unique constr обрабатывается корректно" — Already handled. isUniqueViolation checks pgx error code 23505, then falls back to
  findPendingOrRunningUpdate. Works correctly.

  "Детализировать health-чек" — Partially done already. Your /readyz returns "DB not ready" or "Cache not ready" — it does distinguish which dependency failed.
  The note's assumption that it doesn't is outdated. You could add more detail (latency, error message), but the current state is adequate.

  ---
  Worth implementing

  "Внедрить сквозную трассировку (request_id)" — Valid and high-value. Your UpdateQuotePayload only carries update_id, base, quote. The request_id from the HTTP
  middleware is lost when the task hits the worker. Adding request_id to the payload and logging it in the worker would let you trace a request from API → queue →
   worker → DB in logs. Low effort, high debugging value.

  "Протестировать Postgres-репозиторий" — Valid. Your repository has the most complex logic (SQL queries, type casting, unique constraint handling) and zero test
  coverage. Integration tests with testcontainers-go would catch SQL syntax errors, type mapping bugs, and dedup race conditions that unit tests with mocks can't.
   This is the highest-risk untested code.

  "Протестировать внешний провайдер" — Valid. ExchangeRateHostProvider parses external JSON, and a malformed response or API change would silently break the
  service. An httptest.Server-based test covering success, HTTP errors, bad JSON, and missing rate key is straightforward and worth doing.

  "Протестировать логику кэширования в GetLatestQuote" — Valid. Three scenarios (cache hit, cache miss → DB hit, cache miss → DB miss) are core behavior.
  Currently TestProcessUpdate_Success connects to a real Redis that isn't running, so cache writes silently fail. Using miniredis (in-memory Redis for testing)
  would give you real cache coverage.

  "Реализовать политику очистки старых данных" — Valid for production. The quotes table grows unbounded. A simple approach: a periodic SQL DELETE FROM quotes
  WHERE status IN ('SUCCESS','FAILED') AND updated_at < NOW() - INTERVAL '30 days' run via a cron job or a scheduled asynq task. Not urgent for development, but
  necessary before production.

  "Внедрить метрики (Prometheus)" — Valid for production readiness. Key metrics would be: request latency histogram, queue depth, provider call success/failure
  rate, cache hit ratio. Standard approach: promhttp handler on /metrics, prometheus/client_golang counters/histograms in the service layer. Medium effort, high
  operational value.

  ---
  Not worth implementing (or needs rethinking)

  "Сделать альтернативную батчевую обработку курсов в транзакции" — Doesn't fit the architecture. Your design is one-pair-per-task with dedup. Batch processing
  would require a different API contract (accept multiple pairs), a different task structure, and the external API (exchangerate.host/live) already returns one
  source currency at a time. The complexity doesn't pay off unless you're handling hundreds of pairs simultaneously, and even then you'd batch at the API call
  level, not the DB transaction level.

  "Проверить эвикшн полиси, memory pressure" — Not actionable. You're using Redis with explicit TTLs (cache.ttl_sec), not an in-process cache. Redis handles its
  own eviction via maxmemory-policy (default: noeviction). This is a Redis deployment config concern, not an application code concern. If you're worried, set
  maxmemory and maxmemory-policy allkeys-lru in redis.conf. No code changes needed.

  "Подумать о деплойменте редиса: бэкап, восстановление" — Infrastructure concern, not application code. Your app already handles Redis being unavailable
  gracefully (cache miss → falls through to DB). If Redis restarts with an empty dataset, the cache repopulates organically via read-through. No special recovery
  logic needed in the app. Redis persistence (RDB/AOF) is a deployment decision.

  "Добавить крон обработчик, который обновляет все котировки" — Questionable value. Your service is on-demand by design: users request updates, workers fetch
  them. A cron that refreshes all known pairs would add complexity (tracking which pairs exist, scheduling, rate limiting external calls) for a benefit that's
  only relevant if you need guaranteed freshness without user interaction. If you do want this, asynq's built-in Scheduler is the right tool — but clarify the use
   case first.

  "CORS?" — Only needed if you're serving a browser-based frontend from a different origin. If this is a backend-to-backend API (which the architecture suggests),
   CORS middleware adds nothing. If you do add a frontend later, it's a 5-line chi middleware addition — not worth doing preemptively.

  "Отрисовать схему в красивом виде" — Documentation task, not a code task. Useful for onboarding or a README, but has no impact on the system. Low priority.

  "Атомизировать логику дедупликации в БД" — We discussed this already (the CTE approach). The race window is near-zero in practice because the partial unique
  index guarantees data integrity regardless. The current two-query approach is correct and more readable. Only worth changing if you observe the race condition
  in production metrics.

  "Внедрить механизм отказоустойчивости для внешнего провайдера" — The note says "critical" but the practical options (fallback provider, circuit breaker) all
  require a second rate source, which you don't have. Asynq already retries failed tasks with exponential backoff, which covers transient outages. A circuit
  breaker would prevent hammering a down provider, but asynq's retry backoff largely achieves the same thing. Unless you have a second provider to fall back to,
  the effort-to-value ratio is poor.

  ---
  Summary priority list
  ┌──────────┬───────────────────────────────────────────┬────────────┐
  │ Priority │                   Item                    │   Effort   │
  ├──────────┼───────────────────────────────────────────┼────────────┤
  │ 1        │ Integration tests for Postgres repository │ Medium     │
  ├──────────┼───────────────────────────────────────────┼────────────┤
  │ 2        │ Propagate request_id through asynq tasks  │ Low        │
  ├──────────┼───────────────────────────────────────────┼────────────┤
  │ 3        │ httptest-based provider tests             │ Low        │
  ├──────────┼───────────────────────────────────────────┼────────────┤
  │ 4        │ Cache logic tests with miniredis          │ Low        │
  ├──────────┼───────────────────────────────────────────┼────────────┤
  │ 5        │ Data retention/cleanup policy             │ Low-Medium │
  ├──────────┼───────────────────────────────────────────┼────────────┤
  │ 6        │ Prometheus metrics                        │ Medium     │
  └──────────┴───────────────────────────────────────────┴────────────┘


  ---
  Что можно было бы улучшить:
  - разделить редис на 2 инстанса: один для очередей, один для кэширования
  - реализовать transactional outbox
